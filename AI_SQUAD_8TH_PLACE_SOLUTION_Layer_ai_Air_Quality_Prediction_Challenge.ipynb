{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***This notebook was runned on Google Colab***"
      ],
      "metadata": {
        "id": "IYkg5BnWg4I8"
      },
      "id": "IYkg5BnWg4I8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#        Layer.ai Air Quality Prediction Challenge\n",
        "Can you use Sentinel 5P data to predict air quality in Kampala for AirQo?\n",
        "\n",
        "**Description**\n",
        "\n",
        "\n",
        "AirQo’s air quality sensing network has more than 120 low-cost devices deployed across Uganda, which regulalry sense and report on air quality using the PM2.5 measure.\n",
        "\n",
        "In this challenge we explore using satellite radar data from Sentinel 5P to predict air quality in regions in Kampala. The use of satellite data could expand air quality predictions to areas without air quality sensor devices.\n",
        "\n",
        "The objective of this challenge is to predict air quality readings from AirQo’s sensors using Sentinel 5P data.\n",
        "\n",
        "# Team ; **AI-SQUAD**\n",
        "\n",
        "***position : 8th Place*** \n",
        "\n",
        "Team Members\n",
        "\n",
        "Emmanuel Ebiendele (Ebiendele)\n",
        "\n",
        "Adetoro Michael oluwaferanmi (Mike_ade)\n",
        "\n",
        "Blessing Irenosen (D-PROF)\n",
        "\n",
        "Eromosele Precious Ebiendele (preciousdata)"
      ],
      "metadata": {
        "id": "QO9Cvpi_hA8O"
      },
      "id": "QO9Cvpi_hA8O"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3DewW_cdbkP",
        "outputId": "225e5cc7-b235-4274-c8b8-c13e4f8d9ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1-cp37-none-manylinux1_x86_64.whl (76.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.8 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ],
      "id": "z3DewW_cdbkP"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "91517d92"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.display.max_columns = 999\n",
        "pd.options.display.max_rows = 999\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "id": "91517d92"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "449cb28d"
      },
      "outputs": [],
      "source": [
        "#Label Encoder\n",
        "def label_enc(train_df, test_df, features):\n",
        "    lbl_enc = LabelEncoder()\n",
        "    full_data = pd.concat([train_df[features], test_df[features]],axis=0)\n",
        "    for col in (features):\n",
        "        print(col)\n",
        "        lbl_enc.fit(full_data[col].values)\n",
        "        train_df[col] = lbl_enc.transform(train_df[col])\n",
        "        test_df[col] = lbl_enc.transform(test_df[col])\n",
        "    return train_df, test_df"
      ],
      "id": "449cb28d"
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <br><center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Google_Drive_logo.png/600px-Google_Drive_logo.png' height=\"150\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Mount GDrive to /content/drive</h3></center><br>\n",
        "MODE = \"MOUNT\" #@param [\"MOUNT\", \"UNMOUNT\"]\n",
        "#Mount your Gdrive! \n",
        "from google.colab import drive\n",
        "drive.mount._DEBUG = False\n",
        "if MODE == \"MOUNT\":\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "elif MODE == \"UNMOUNT\":\n",
        "  try:\n",
        "    drive.flush_and_unmount()\n",
        "  except ValueError:\n",
        "    pass\n",
        "  get_ipython().system_raw(\"rm -rf /root/.config/Google/DriveFS\")"
      ],
      "metadata": {
        "id": "LN4A1rGN1T7C",
        "outputId": "9f9050ce-6316-4a7b-b17e-6f287fe75a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LN4A1rGN1T7C",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "path = '/content/drive/MyDrive/layer_data'\n",
        "train_df = pd.read_csv(f'{path}/train.csv')\n",
        "test_df = pd.read_csv(f'{path}/test.csv')\n",
        "sub = pd.read_csv(f'{path}/SampleSubmission.csv')"
      ],
      "metadata": {
        "id": "eAi_7UaX10Wm"
      },
      "id": "eAi_7UaX10Wm",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "11171413-3d99-4c74-9ca0-b9acdbba0c51"
      },
      "outputs": [],
      "source": [
        "# test_df.columns"
      ],
      "id": "11171413-3d99-4c74-9ca0-b9acdbba0c51"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0XbVxngY6vtq"
      },
      "outputs": [],
      "source": [
        "col1 = ['ID','date']\n",
        "col2 = ['device']\n",
        "col3 = ['humidity', 'temp_mean']\n",
        "location = ['site_latitude', 'site_longitude']\n",
        "chem = [\n",
        "        'SulphurDioxide_SO2_column_number_density',\n",
        "       'SulphurDioxide_SO2_column_number_density_amf',\n",
        "        'SulphurDioxide_SO2_column_number_density_15km',\n",
        "       'CarbonMonoxide_CO_column_number_density',\n",
        "        'NitrogenDioxide_NO2_column_number_density',\n",
        "        'UvAerosolIndex_absorbing_aerosol_index',\n",
        "        'Ozone_O3_column_number_density',\n",
        "        'Cloud_cloud_fraction', \n",
        "        'Cloud_cloud_top_pressure'\n",
        "]\n",
        "target = ['pm2_5']\n",
        "feat = col1 + col2 + col3 + location + chem\n",
        "train_df = train_df[feat + target]\n",
        "test_df = test_df[feat]"
      ],
      "id": "0XbVxngY6vtq"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "067db8de-b4d9-4595-9e14-db599bc7bf64",
        "outputId": "e9620e08-18f8-4136-ddc9-a3871e81cc4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9923, 17), (4254, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "id": "067db8de-b4d9-4595-9e14-db599bc7bf64"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be527b52"
      },
      "source": [
        "# Add The Time Features"
      ],
      "id": "be527b52"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F4G08TcxONaO"
      },
      "outputs": [],
      "source": [
        "# train_df = train_df[train_df.pm2_5 < 220]"
      ],
      "id": "F4G08TcxONaO"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4386282b"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sort_values(['date', 'device']).reset_index(drop=True) \n",
        "test_df = test_df.sort_values(['date', 'device']).reset_index(drop=True)\n",
        "\n",
        "for dataset in (train_df,test_df):\n",
        "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "    dataset['Day'] = dataset.date.dt.day\n",
        "    dataset['Month'] = dataset.date.dt.month\n",
        "    dataset['Year'] = dataset.date.dt.year\n",
        "    dataset['DayOfWeek'] = dataset.date.dt.dayofweek\n",
        "    dataset['DayOfYear'] = dataset.date.dt.dayofyear\n",
        "    dataset['Week'] = dataset.date.dt.weekofyear\n",
        "    dataset.set_index('date', inplace=True)"
      ],
      "id": "4386282b"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c5f92c3a"
      },
      "outputs": [],
      "source": [
        "ID = test_df['ID']\n",
        "test_df.drop('ID',inplace=True,axis=1)\n",
        "train_df.drop('ID',inplace=True,axis=1)"
      ],
      "id": "c5f92c3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53857f36"
      },
      "source": [
        "# Exploratory data analysis"
      ],
      "id": "53857f36"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbfef88f",
        "outputId": "9a177bf9-fed9-4628-c0b2-511033e2df52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4254, 20), (9923, 21))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "test_df.shape, train_df.shape"
      ],
      "id": "dbfef88f"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9783ebdf"
      },
      "outputs": [],
      "source": [
        "num_col = train_df.select_dtypes(exclude='O').columns.difference(['Month', 'pm2_5', 'site_latitude', 'site_longitude', 'humidity', 'temp_mean', 'Day', 'DayOfWeek', 'DayOfYear', 'Year', 'Week'])\n",
        "train_df.temp_mean = train_df.temp_mean.fillna(train_df.temp_mean.median())\n",
        "for data in (train_df, test_df):\n",
        "    for feat in num_col:\n",
        "        data[feat] = data[feat].bfill()"
      ],
      "id": "9783ebdf"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "37916f9d"
      },
      "outputs": [],
      "source": [
        "def LAG(data,LagFeature,shift=1,NewFeatures=[]) :\n",
        "    data[NewFeatures[0]]   = data[LagFeature]  - data[LagFeature].shift(shift)\n",
        "    data[NewFeatures[1]]   = data[LagFeature].shift(shift)\n",
        "\n",
        "num_feats = train_df.columns\n",
        "num_feats = num_feats.drop(['DayOfWeek','Month','Day','pm2_5','temp_mean','humidity','site_longitude', 'site_latitude','device', 'Year', 'DayOfYear', 'Week'])\n",
        "\n",
        "for feature in num_feats:\n",
        "    LAG(train_df,LagFeature=f'{feature}',shift=1,NewFeatures=[f'{feature}_diff_Lag1',f'{feature}_Lag1'])\n",
        "    LAG(test_df,LagFeature=f'{feature}',shift=1,NewFeatures=[f'{feature}_diff_Lag1',f'{feature}_Lag1'])"
      ],
      "id": "37916f9d"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cba07fe",
        "outputId": "d2115ef9-38db-49ec-a639-3719df547562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year_Month\n",
            "Year_Week\n",
            "Month_Day\n",
            "device\n",
            "lat_lon\n"
          ]
        }
      ],
      "source": [
        "for dataset in (train_df,test_df):\n",
        "    dataset['Year_Month'] = dataset['Year'].astype(str) + '-' + dataset['Month'].astype(str)\n",
        "    dataset['Year_Week'] = dataset['Year'].astype(str) + '-' + dataset['Week'].astype(str)\n",
        "    dataset['Month_Day'] = dataset['Month'].astype(str) + '-' + dataset['Day'].astype(str)\n",
        "    dataset['lat_lon'] = dataset['site_latitude'].astype(str) + '_' + dataset['site_longitude'].astype(str)\n",
        "    \n",
        "feats = ['Year_Month','Year_Week','Month_Day', 'device',\n",
        "         'lat_lon'\n",
        "        ]\n",
        "train_df,test_df = label_enc(train_df,test_df,feats)"
      ],
      "id": "5cba07fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6099d339"
      },
      "source": [
        "## - Aggregations Features"
      ],
      "id": "6099d339"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ba255c96"
      },
      "outputs": [],
      "source": [
        "DevicePM2_5Mean = dict(train_df.groupby('device')['pm2_5'].mean())\n",
        "DevicePM2_5Std = dict(train_df.groupby('device')['pm2_5'].std())\n",
        "DevicePM2_5Min = dict(train_df.groupby('device')['pm2_5'].min())\n",
        "DevicePM2_5Max = dict(train_df.groupby('device')['pm2_5'].max())\n",
        "\n",
        "for dataset in (train_df,test_df):\n",
        "    dataset['DevicePM2_5Mean'] = dataset['device'].map(DevicePM2_5Mean)\n",
        "    dataset['DevicePM2_5Std'] = dataset['device'].map(DevicePM2_5Std)\n",
        "    dataset['DevicePM2_5Min'] = dataset['device'].map(DevicePM2_5Min)\n",
        "    dataset['DevicePM2_5Max'] = dataset['device'].map(DevicePM2_5Max)"
      ],
      "id": "ba255c96"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e2683617"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([train_df, test_df], axis = 0)\n",
        "def Agg(Features):\n",
        "    for dataset in (train_df,test_df):\n",
        "        for Feature in Features:\n",
        "            dataset[f'{Feature}_PerMonth'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].mean()))\n",
        "            dataset[f'{Feature}_PerWeek'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].mean()))\n",
        "            dataset[f'{Feature}_PerDay'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].mean()))\n",
        "\n",
        "            dataset[f'{Feature}_Month_std'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].std()))\n",
        "            dataset[f'{Feature}_Week_std'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].std()))\n",
        "            dataset[f'{Feature}_Day_std'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].std()))\n",
        "\n",
        "            dataset[f'{Feature}_Month_min'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].min()))\n",
        "            dataset[f'{Feature}_Week_min'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].min()))\n",
        "            dataset[f'{Feature}_Day_min'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].min()))\n",
        "\n",
        "            dataset[f'{Feature}_Month_max'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].max()))\n",
        "            dataset[f'{Feature}_Week_max'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].max()))\n",
        "            dataset[f'{Feature}_Day_max'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].max()))\n",
        "        \n",
        "Agg(['temp_mean', 'humidity'])"
      ],
      "id": "e2683617"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8521e5e-95a5-433a-a578-5cffc50b5851",
        "outputId": "b53931ac-cce7-4118-fab1-17090d7bed2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9923, 71), (4254, 70))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "id": "c8521e5e-95a5-433a-a578-5cffc50b5851"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6acdf188-2a25-4833-811c-05b412e3c7b9"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.fillna(0)\n",
        "test_df = test_df.fillna(0)"
      ],
      "id": "6acdf188-2a25-4833-811c-05b412e3c7b9"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1bd36e4e"
      },
      "outputs": [],
      "source": [
        "train_df.drop(['Year_Month','Year_Week','Month_Day'],inplace=True,axis=1)\n",
        "test_df.drop(['Year_Month','Year_Week','Month_Day'],inplace=True,axis=1)\n",
        "\n",
        "train_df.drop(['site_longitude', 'site_latitude'],inplace=True,axis=1)\n",
        "test_df.drop(['site_longitude', 'site_latitude'],inplace=True,axis=1)"
      ],
      "id": "1bd36e4e"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FcGRdk9yuQnQ"
      },
      "outputs": [],
      "source": [
        "#Averaging the predictions of the same model with different seeds to get more consistent results\n",
        "X = train_df.drop('pm2_5', axis = 1)\n",
        "y = train_df.pm2_5"
      ],
      "id": "FcGRdk9yuQnQ"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aa897e6-4125-4e58-9d2d-87bf91a0ba1a",
        "outputId": "94586897-3a89-4b53-95df-ef29d436692f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9923, 65), (9923,), (4254, 65))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "X.shape, y.shape, test_df.shape"
      ],
      "id": "6aa897e6-4125-4e58-9d2d-87bf91a0ba1a"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ecadbfdc-ee52-430d-b865-ba8e518fc0ac"
      },
      "outputs": [],
      "source": [
        "# X_train, y_train = X[:9000], y[:9000]\n",
        "# X_test, y_test = X[9000:], y[9000:]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1, shuffle = True, random_state = 42)"
      ],
      "id": "ecadbfdc-ee52-430d-b865-ba8e518fc0ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e52efdb8"
      },
      "source": [
        "# Modeling"
      ],
      "id": "e52efdb8"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b37e0907-2b4c-4c39-be17-394885013e9e",
        "outputId": "f0ad9a64-18b2-472d-e003-65e450957a7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.255595074998711"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "cb = CatBoostRegressor(n_estimators = 10303, learning_rate = 0.028926897706232692, depth = 8, verbose = 0, random_state = 42)\n",
        "model = TransformedTargetRegressor(cb, func = np.log1p, inverse_func = np.expm1)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "mae(y_test, pred)"
      ],
      "id": "b37e0907-2b4c-4c39-be17-394885013e9e"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "G-nWuS2Hj987"
      },
      "outputs": [],
      "source": [
        "pred_1 = model.predict(test_df)\n",
        "# pred_2 = LogCB.predict(test_df)\n",
        "submission = pd.DataFrame({\"Id\": ID ,\"pm2_5\": pred_1})\n",
        "submission.to_csv('/content/drive/MyDrive/layer_data/laisq.csv', index = False)"
      ],
      "id": "G-nWuS2Hj987"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRIVATE LEADERBOARD SCORE: 12.82981740718469**"
      ],
      "metadata": {
        "id": "JcxUloV8i-0w"
      },
      "id": "JcxUloV8i-0w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMwPj82VrFnk"
      },
      "outputs": [],
      "source": [],
      "id": "kMwPj82VrFnk"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}